{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **My First ML Project**\n"
      ],
      "metadata": {
        "id": "4nsnfxWIPPx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cell 1: Setup and Data Generators**"
      ],
      "metadata": {
        "id": "K3hTtsnwQZ1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Phf1-9JNo-_"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Define image dimensions, batch size, and number of epochs\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set dataset directories (adjust these paths if needed)\n",
        "dataset_path = '/content/drive/MyDrive/butterfly_vs_moth'\n",
        "train_dir = '/content/drive/MyDrive/butterfly_vs_moth/train'\n",
        "validation_dir = '/content/drive/MyDrive/butterfly_vs_moth/validation'\n",
        "model_path = '/content/drive/MyDrive/butterfly_vs_moth_model.h5'\n",
        "\n",
        "#  Reload Model If It Exists (Prevents Retraining from Scratch)\n",
        "if os.path.exists(model_path):\n",
        "    print(\" Loading saved model...\")\n",
        "    model = load_model(model_path)\n",
        "    print(\" Model loaded successfully!\")\n",
        "else:\n",
        "    print(\" No saved model found. Training a new model...\")\n",
        "\n",
        "\n",
        "# Create ImageDataGenerators for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Flow images from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Print number of classes\n",
        "num_classes = train_generator.num_classes\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cell 2: Build and Train the Model**"
      ],
      "metadata": {
        "id": "8X24VYZU3r65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using transfer learning with MobileNetV2\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "base_model.trainable = False  # Freeze the base model for faster training\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "# Final layer with softmax activation for 10 classes\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Save the trained model to Google Drive so it persists beyond your session\n",
        "model_save_path = '/content/drive/MyDrive/butterfly_vs_moth_model.h5'\n",
        "model.save(model_save_path)\n",
        "print(\"Model training complete and saved to\", model_save_path)\n"
      ],
      "metadata": {
        "id": "7tXGgrU-3wba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 3: Inference Example**"
      ],
      "metadata": {
        "id": "w3wQgqXa37GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import additional libraries for inference\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load a sample image from the validation set (change index as needed)\n",
        "sample_img_path = validation_generator.filepaths[0]   # First image in the validation set\n",
        "print(\"Sample image path:\", sample_img_path)\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = image.load_img(sample_img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "# Predict the class of the sample image\n",
        "preds = model.predict(img_array)\n",
        "predicted_class = np.argmax(preds, axis=1)\n",
        "print(\"Predicted class index:\", predicted_class)\n",
        "\n",
        "# Display the mapping from class indices to folder names\n",
        "print(\"Class mapping:\", train_generator.class_indices)\n"
      ],
      "metadata": {
        "id": "Hmwatf8N4Lr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OAhN20rQ4QvW"
      }
    }
  ]
}